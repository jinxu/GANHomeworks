{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Мета:\n",
    "\n",
    "Дослідити різні архітектури генеративно-змагальних мереж (GAN) і практикуватися з налаштуванням параметрів для досягнення кращих результатів генерації зображень.\n",
    "\n",
    "Кроки для виконання завдання:\n",
    "\n",
    "1. Вибір архітектур GAN:\n",
    "  * DCGAN (Deep Convolutional GAN): Реалізуйте DCGAN, що використовує згорткові шари для кращого захоплення просторових властивостей зображень.\n",
    "  * WGAN (Wasserstein GAN): Спробуйте реалізувати WGAN для покращення стабільності навчання та якості генерації.\n",
    "  * Conditional GAN (cGAN): Реалізуйте Conditional GAN, щоб навчитися генерувати зображення з додатковими умовами (наприклад, категорією).\n",
    "2. Підготовка набору даних:\n",
    "  * Як в попереднізавданнях\n",
    "3. Налаштування архітектури кожного GAN:\n",
    "  * Генератор: Експериментуйте з кількістю шарів, розмірами фільтрів, активаціями (наприклад, ReLU, LeakyReLU).\n",
    "  * Дискримінатор: Вивчіть вплив використання різних функцій активації, шару нормалізації пакетів (Batch Normalization) тощо.\n",
    "  * Вибір функцій втрат: Для кожної архітектури використовуйте відповідні функції втрат (наприклад, binary cross-entropy для базового GAN, Wasserstein loss для WGAN).\n",
    "4. Методи налаштування (fine-tuning):\n",
    "  * Розмір батчу: Спробуйте різні розміри батчу для кращої стабільності навчання.\n",
    "  * Коефіцієнт навчання: Експериментуйте з різними значеннями коефіцієнта навчання (learning rate) для генератора і дискримінатора.\n",
    "  * Регуляризація: Додайте Dropout до дискримінатора, щоб запобігти перенавчанню.\n",
    "  * Зміна оптимізаторів: Використайте оптимізатори Adam, RMSprop або інші для покращення швидкості збіжності.\n",
    "5. Навчання та порівняння архітектур:\n",
    "  * Навчіть кожну з архітектур на одному наборі даних для порівняння результатів.\n",
    "  * Періодично зберігайте згенеровані зображення для візуальної оцінки прогресу.\n",
    "6. Оцінка та візуалізація результатів:\n",
    "  * Візуалізуйте згенеровані зображення для кожної з архітектур GAN.\n",
    "  * Порівняйте результати на основі якості та різноманітності згенерованих зображень.\n",
    "  * Проведіть аналіз, яка архітектура дає найкращі результати для обраного набору даних.\n",
    "7. Документування висновків:\n",
    "  * Оцініть, яка архітектура показала найкращі результати, та опишіть, чому це сталося.\n",
    "  * Опишіть, які методи налаштування мали найбільший вплив на продуктивність моделей.\n",
    "\n",
    "Мінімальні вимоги:\n",
    "\n",
    "* Реалізувати та налаштувати принаймні дві різні архітектури GAN.\n",
    "* Візуально оцінити та порівняти результати кожної архітектури.\n",
    "\n",
    "Додаткові рекомендації:\n",
    "\n",
    "* Експериментуйте з використанням більш складних наборів даних для оцінки ефективності кожної архітектури.\n",
    "\n",
    "Формат виконання: \n",
    "\n",
    ".ipynb блокнот з кодом та візуалізацією, або ж код в .py з прикріпленими зображеннями результатів на гітхабі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load your dataset here (example with CIFAR-10)\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch [0/391] d_loss: 1.3821 g_loss: 3.4049\n",
      "Epoch [0/5] Batch [100/391] d_loss: 0.3620 g_loss: 0.5470\n",
      "Epoch [0/5] Batch [200/391] d_loss: 0.3008 g_loss: 3.4415\n",
      "Epoch [0/5] Batch [300/391] d_loss: 0.8480 g_loss: 2.1030\n",
      "Epoch [1/5] Batch [0/391] d_loss: 1.0325 g_loss: 5.5890\n",
      "Epoch [1/5] Batch [100/391] d_loss: 0.3986 g_loss: 3.5943\n",
      "Epoch [1/5] Batch [200/391] d_loss: 0.8033 g_loss: 1.8956\n",
      "Epoch [1/5] Batch [300/391] d_loss: 0.3237 g_loss: 3.4196\n",
      "Epoch [2/5] Batch [0/391] d_loss: 0.9655 g_loss: 0.5806\n",
      "Epoch [2/5] Batch [100/391] d_loss: 0.5430 g_loss: 2.7731\n",
      "Epoch [2/5] Batch [200/391] d_loss: 0.3582 g_loss: 4.3093\n",
      "Epoch [2/5] Batch [300/391] d_loss: 0.6665 g_loss: 3.9667\n",
      "Epoch [3/5] Batch [0/391] d_loss: 0.0643 g_loss: 4.2148\n",
      "Epoch [3/5] Batch [100/391] d_loss: 0.3651 g_loss: 4.5731\n",
      "Epoch [3/5] Batch [200/391] d_loss: 0.4907 g_loss: 4.7940\n",
      "Epoch [3/5] Batch [300/391] d_loss: 1.2277 g_loss: 5.7699\n",
      "Epoch [4/5] Batch [0/391] d_loss: 0.4882 g_loss: 4.0337\n",
      "Epoch [4/5] Batch [100/391] d_loss: 0.2296 g_loss: 3.2130\n",
      "Epoch [4/5] Batch [200/391] d_loss: 0.4634 g_loss: 4.5293\n",
      "Epoch [4/5] Batch [300/391] d_loss: 0.2867 g_loss: 3.1694\n"
     ]
    }
   ],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is latent_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # State size: 512 x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # State size: 256 x 8 x 8\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # State size: 128 x 16 x 16\n",
    "            nn.ConvTranspose2d(128, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output size: channels x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input size: channels x 32 x 32\n",
    "            nn.Conv2d(channels, 128, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: 128 x 16 x 16\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: 512 x 4 x 4\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1).squeeze(1)\n",
    "\n",
    "# Training setup\n",
    "def train_dcgan(dataloader, num_epochs=100, latent_dim=100):    \n",
    "    # Initialize networks\n",
    "    generator = Generator(latent_dim).to(DEVICE)\n",
    "    discriminator = Discriminator().to(DEVICE)\n",
    "    \n",
    "    # Setup optimizers\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_label = torch.ones(batch_size).to(DEVICE)\n",
    "            fake_label = torch.zeros(batch_size).to(DEVICE)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            real_images = real_images.to(DEVICE)\n",
    "            d_optimizer.zero_grad()\n",
    "            output = discriminator(real_images)\n",
    "            d_loss_real = criterion(output, real_label)\n",
    "            \n",
    "            noise = torch.randn(batch_size, latent_dim, 1, 1).to(DEVICE)\n",
    "            fake_images = generator(noise)\n",
    "            output = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(output, fake_label)\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            output = discriminator(fake_images)\n",
    "            g_loss = criterion(output, real_label)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
    "                      f'd_loss: {d_loss.item():.4f} g_loss: {g_loss.item():.4f}')\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Train the model\n",
    "generatorDGAN, discriminatorDGAN = train_dcgan(dataloader,num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch [0/391] Critic Loss: -29.4890 Generator Loss: 19.7102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Critic, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(channels, 128, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, 1, 0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)\n",
    "\n",
    "def train_wgan(dataloader, num_epochs=100, latent_dim=100, critic_iterations=5, clip_value=0.01):    \n",
    "    generator = Generator(latent_dim).to(DEVICE)\n",
    "    critic = Critic().to(DEVICE)\n",
    "    \n",
    "    g_optimizer = optim.RMSprop(generator.parameters(), lr=0.00005)\n",
    "    c_optimizer = optim.RMSprop(critic.parameters(), lr=0.00005)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(DEVICE)\n",
    "            \n",
    "            # Train Critic\n",
    "            for _ in range(critic_iterations):\n",
    "                noise = torch.randn(batch_size, latent_dim, 1, 1).to(DEVICE)\n",
    "                fake_images = generator(noise)\n",
    "                \n",
    "                c_optimizer.zero_grad()\n",
    "                \n",
    "                # Wasserstein loss\n",
    "                critic_real = critic(real_images).mean()\n",
    "                critic_fake = critic(fake_images.detach()).mean()\n",
    "                critic_loss = -critic_real + critic_fake\n",
    "                \n",
    "                critic_loss.backward()\n",
    "                c_optimizer.step()\n",
    "                \n",
    "                # Weight clipping\n",
    "                for p in critic.parameters():\n",
    "                    p.data.clamp_(-clip_value, clip_value)\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_images = generator(noise)\n",
    "            generator_loss = -critic(fake_images).mean()\n",
    "            \n",
    "            generator_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
    "                      f'Critic Loss: {critic_loss.item():.4f} '\n",
    "                      f'Generator Loss: {generator_loss.item():.4f}')\n",
    "    \n",
    "    return generator, critic\n",
    "\n",
    "# Data loading and training setup\n",
    "\n",
    "generatorWGAN, criticWGAN = train_wgan(dataloader,num_epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample images\n",
    "def generate_samples(generator, latent_dim=100, num_samples=16):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, latent_dim, 1, 1).to(DEVICE)\n",
    "        fake_images = generator(noise)\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import torchvision.utils as vutils\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(vutils.make_grid(\n",
    "            fake_images.cpu(), padding=2, normalize=True), (1,2,0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "generate_samples(generatorDGAN)\n",
    "generate_samples(generatorWGAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key differences WGAN from DCGAN:\n",
    "\n",
    "Uses a Critic instead of Discriminator (no sigmoid at the end)\n",
    "Implements Wasserstein loss instead of BCE\n",
    "Uses weight clipping for Lipschitz constraint\n",
    "Employs RMSprop optimizer instead of Adam\n",
    "Multiple critic updates per generator update\n",
    "Uses InstanceNorm instead of BatchNorm in the critic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
